function loglikelihood(prob, individual, z, Ïƒ)
    yÌ‚ = predict_adjoint(prob, individual, z)
    Î£ = fill(Ïƒ, length(yÌ‚))
    return logpdf(MultivariateNormal(yÌ‚, Î£), individual.y)
end
logprior(Î·::AbstractVector, Î©::AbstractMatrix) = logpdf(MultivariateNormal(zero.(Î·), Î©), Î·)
logjoint(model, individual, z, Î·, Î©, Ïƒ) = loglikelihood(model, individual, z, Ïƒ) + logprior(Î·, Î©)

_chol_lower(a::Cholesky) = a.uplo === 'L' ? a.L : a.U'
function partial_advi(model, population, p, phi::NamedTuple; num_samples = 1, with_entropy = false)
    m = 2 # num_rand_effects
    # Î¶, _ = Lux.apply(model.ann, population.x, p.weights, p.st) # Lux
    Î¶, _ = model.ann(Zygote.ignore_derivatives(population.x), p.weights, Zygote.ignore_derivatives(p.st)) # Lux
    Ïƒ_Ï‰ = softplus.([p.error.sigma; p.omega.var])
    Ïƒ = Ïƒ_Ï‰[1]
    Ï‰ = Ïƒ_Ï‰[2:3]
    C = inverse(Bijectors.VecCorrBijector())(p.omega.corr)
    Î© = Symmetric(Ï‰ .* C .* Ï‰')

    ELBO = zero(eltype(Î¶))
    for _ in 1:num_samples
        for i in eachindex(population)
            # Calculates p(y | Î·; Ïƒ) + p(Î·; Î©) - q_ğœ™(Î·)
            Láµ¢ = LowerTriangular(_chol_lower(inverse(Bijectors.VecCholeskyBijector(:L))(phi.corr[:, i])) .* softplus.(phi.sigma[:, i]))
            Î·áµ¢ = phi.mean[:, i] + Láµ¢ * randn(Float32, m)
            záµ¢ = Î¶[:, i] .* exp.([1 0; 0 1; 0 0; 0 0] * Î·áµ¢)
            logÏ€ = logjoint(model.problem, population[i], záµ¢, Î·áµ¢, Î©, Ïƒ)
            qáµ¢ = @ignore_derivatives MultivariateNormal(phi.mean[:, i], Láµ¢ * Láµ¢')
            ELBO += (logÏ€ - logpdf(qáµ¢, Î·áµ¢)) / num_samples
        end
    end
    
    return ELBO
end

function predict_adjoint(prob, individual::AbstractIndividual, z::AbstractVector{T}; measurement_idx = 1) where T
    prob_ = remake(prob, tspan = (prob.tspan[1], maximum(individual.t)), p = [z; zero(T)])
    return solve(
        prob_, Tsit5(), dtmin=1e-10, saveat=individual.t, 
        tstops=individual.callback.condition.times, callback=individual.callback, 
        sensealg=ForwardDiffSensitivity(;convert_tspan=true)
    )[measurement_idx, :]
end


function partial_advi_(ann, prob, population, ğœ™::NamedTuple, st; num_samples = 1, with_entropy = false)
    m = 2 # num_rand_effects
    Î¶, _ = Lux.apply(ann, Zygote.ignore_derivatives(population.x), ğœ™.weights, st) # Lux
    Ïƒ_Ï‰ = softplus.(ğœ™.theta[1:3])
    Ïƒ = Ïƒ_Ï‰[1]
    Ï‰ = Ïƒ_Ï‰[2:3]
    C = inverse(Bijectors.VecCorrBijector())(ğœ™.theta[4:end])
    Î© = Symmetric(Ï‰ .* C .* Ï‰')

    ELBO = zero(eltype(Î¶))
    for _ in 1:num_samples
        for i in eachindex(population)
            # Calculates p(y | Î·; Ïƒ) + p(Î·; Î©) - q_ğœ™(Î·)
            Láµ¢ = LowerTriangular(_chol_lower(inverse(Bijectors.VecCholeskyBijector(:L))(ğœ™.phi[2m+1:end, i])) .* softplus.(ğœ™.phi[m+1:2m, i]))
            Î·áµ¢ = ğœ™.phi[1:m, i] + Láµ¢ * randn(Float32, m)
            záµ¢ = Î¶[:, i] .* exp.([1 0; 0 1; 0 0; 0 0] * Î·áµ¢)
            logÏ€ = logjoint(prob, population[i], záµ¢, Î·áµ¢, Î©, Ïƒ)
            qáµ¢ = @ignore_derivatives MultivariateNormal(ğœ™.phi[1:2, i], Láµ¢ * Láµ¢')
            ELBO += (logÏ€ - logpdf(qáµ¢, Î·áµ¢)) / num_samples
        end
    end
    
    return ELBO
end